import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, cross_val_score
from joblib import dump
from data_preprocessing import data_preprocessing

# âœ… Load Processed Data
X, y = data_preprocessing("cleaned_data.csv")

if X is None or y is None:
    raise ValueError("âŒ ERROR: Data preprocessing failed! Exiting script.")

# âœ… Split Data into Train & Test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"âœ… Data Split: Train size = {X_train.shape}, Test size = {X_test.shape}")

# âœ… Train XGBoost Model
model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=6, learning_rate=0.1)
model.fit(X_train, y_train)

# âœ… Model Evaluation
r2 = model.score(X_test, y_test)
mse = np.mean((model.predict(X_test) - y_test) ** 2)
mae = np.mean(np.abs(model.predict(X_test) - y_test))

# âœ… Cross-Validation
cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')

# ğŸ“Š Print Results
print(f"ğŸ“Š XGBoost Performance:")
print(f"ğŸ”¹ R2 Score: {r2:.4f} âœ… (Optimized)")
print(f"ğŸ”¹ MSE: {mse:.4f}")
print(f"ğŸ”¹ MAE: {mae:.4f}")
print(f"ğŸ”¹ Cross-Validation Mean R2: {cv_scores.mean():.4f}")

# âœ… Save Model
dump(model, "models/xgboost_model.joblib")
print("âœ… Model Saved Successfully!")
